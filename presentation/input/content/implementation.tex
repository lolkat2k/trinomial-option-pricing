\section{Part II: Implementation in CUDA}

%% translating map
\begin{frame}[fragile]
  \frametitle{map f xs ys}
%
Inherently parallel operator, as each thread can apply the same input
function to different data.
%
\begin{lstlisting}
let map_lens =
  map (\m i ->
    if i < optionsInChunk
    then 2 * m + 1
    else 0)
  ms (iota maxOptionsInChunk)
\end{lstlisting}
%
\end{frame}

%% translating scatter
\begin{frame}[fragile]
  \frametitle{scatter as is vs}
%
Inherently parallel (assume no duplicates in index?) as each thread
handles the write of one value.
%
%
\begin{lstlisting}
let alphass = scatter
  alphass          -- size: n
  alpha_inds       -- size: k
  alpha_vals       -- size: k
\end{lstlisting}
%
\end{frame}

%% translating scan
\begin{frame}[fragile]
  \frametitle{scan}
%
We are only concerned with inclusive scans for this particular project. 
Use a segmented scan to flatten and apply scan to all elements in lists of lists.
%
%
\begin{lstlisting}
xs = [[1,3,5,10],[2,0,4]]
flags = [4,0,0,0,3,0,0]
scan (+) xs flags = [1, 4, 9, 19, 2, 2, 6]
\end{lstlisting}
\end{frame}

%% memory management
\begin{frame}
  \frametitle{Memory management}
  %
  \begin{itemize}
    \item Memory hierarchies in the CUDA programming model
    \item How we use the different levels in our program
    \item (Shared mem. per thread?)
    \item Optimisation:
      %
      \begin{itemize}
        \item Allocation
        \item Access / pattern (tiling-ish)
      \end{itemize}
      %
  \end{itemize}
\end{frame}
