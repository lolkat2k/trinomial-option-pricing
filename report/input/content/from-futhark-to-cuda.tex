\section{Implementation in CUDA}

The project task is to develop a CUDA implementation
semantically equivalent to the flat Futhark version. This is
simply a one-to-one translation from Futhark to CUDA of the
function \texttt{trinomialChunk}, except for the fact that
memory management in CUDA is explicit and thus needs to be
handled. This leads to optimization considerations as well.

In the following we describe in detail both the simple
translation task along with the memory management and
optimization considerations.


\subsection{Translating from Futhark to CUDA}

In this section we describe the translations of the Futhark
second-order array combinators \texttt{map} and
\texttt{scatter} to semantically equivalent CUDA
code. Furthermore, we also address some problems with a
block-level segmented scan that was provided to us. For more
information on Futhark SOACs see~\cite{futharkdoc}.

\subsubsection{Translating \texttt{map}}

The map operator is inherently data-parallel as one thread
can apply the input function to one element in the array in
parallel. Therefore the body of a map can simply be written
inside the kernel. We show an example of how this
translation is done in Figure~\ref{fig:trans_map}. Note,
that the map operator in Futhark is able to take multiple
input arrays.
%
\begin{figure}[bt]
\begin{center}
%% Futhark
\begin{minipage}[t]{0.45\linewidth}
\vspace{0pt}
\begin{lstlisting}
let map_lens = map
  (\m i -> if i < optionsInChunk
           then 2*m + 1
           else 0
  )
ms (iota maxOptionsInChunk)
\end{lstlisting}
\end{minipage}
%% CUDA
\begin{minipage}[t]{0.45\linewidth}
\vspace{0pt}
\begin{lstlisting}
if(threadIdx.x <
   options_in_chunk)
{
  map_lens[threadIdx.x] =
    2 * ms[threadIdx.x] + 1;
} else {
  map_lens[threadIdx.x] = 0;
}
\end{lstlisting}
\end{minipage}
\caption{Translating \texttt{maps} from Futhark (left) to
  CUDA (right).}
\label{fig:trans_map}
\end{center}
\end{figure}
%




\subsubsection{Translating \texttt{scatter}}

The scatter operator, written \lstinline{scatter arr is vs},
writes the values of \lstinline{vs} at indices
\lstinline{is} to the same indices in \lstinline{arr}. It is
then inherently data-parallel assuming undefined behaviour
if the index array has duplicates.

In absence of duplicate indices no thread reads from nor
writes to the same indices in the value and destination
arrays, respectively. This can also be seen as an in-place
update. In Figure~\ref{fig:trans_scatter} we show how a
scatter in Futhark can be translated to CUDA.
%
\begin{figure}[bt]
\begin{center}
%% Futhark
\begin{minipage}[t]{0.45\linewidth}
\vspace{0pt}
\begin{lstlisting}
let alphass = scatter
              alphass
              alpha_inds
              alpha_vals
\end{lstlisting}
\end{minipage}
%% CUDA
\begin{minipage}[t]{0.45\linewidth}
\vspace{0pt}
\begin{lstlisting}
alphass[threadIdx.x] =
  alpha_vals[
    alpha_inds[threadIdx.x]
  ];
\end{lstlisting}
\end{minipage}
\caption{Translating \texttt{scatter} from Futhark (left) to
  CUDA (right).}
\label{fig:trans_scatter}
\end{center}
\end{figure}
%%


\subsubsection{Translating \texttt{scan}}

When calculating interest rate trees it seems very preferable to
have a block-level segmented scan operator at your disposal.
One was provided for us, but unfortunately the handed out code caused what
seems like race-conditions, that we were not able to correct.

The current implementation circumvent this problem by using
a single thread performing a sequential block-level scan.
Ofcourse this is not in the spirit of parallel programming,
and should be regarded as a quick fix that allowed us to progress
in getting the code to validate.


\subsection{Shared memory management}

Memory access and memory usage are almost always a concern and
programming for GPUs is no exception. Scarcity of resources
and penalty for suboptimal access can have a huge impact on
programs running on GPUs, which becomes evident when the
goal is fast programs.

The CUDA programming model have an overall memory hierarchy
in three levels:
%
\begin{description}
  \item[thread-level]
  \item[block-level]
  \item[]
\end{description}
%
